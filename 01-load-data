library(tidyverse)
library(jsonlite)
library(ggplot2)

#clear workspace
rm(list = ls())

setwd("/Users/OliverHutton1/Downloads")

file_path <- "sessionInfo"

# Recursively find all JSON files under 'sessionInfo'
json_files <- list.files(path = file_path, 
                         pattern = "\\.json$", 
                         full.names = TRUE, 
                         recursive = TRUE)

results <- list()

for (i in seq_along(json_files)) {
  file_path <- json_files[i]
  try({
    tmp <- fromJSON(txt = file_path)
    items_df <- tmp$elements$items[[1]]
    interaction_row <- items_df[!is.na(items_df$interactionType), ]
    out <- tibble(
      file = basename(file_path),
      correct_answer = tmp$scoring$marksEarned,
      hints_requested = tmp$scoring$penalties$hintsRequested,
      content = interaction_row$interactionType,
      maybe_person_id = interaction_row$id
      #marks_total = tmp$scoring$marksTotal only adds a column of 1s
    )
    results[[i]] <- out
  }, silent = TRUE)
}

# Combine all extracted rows into a single data frame
data_raw <- bind_rows(results)

#extract all events and timestamps for each session
extract_events_from_file <- function(file_path) {
  tryCatch({
    tmp <- fromJSON(file_path)
    # Extract creation timestamp and convert to POSIX
    creation_ts <- tmp$creationTimestamp
    session_id <- tools::file_path_sans_ext(basename(file_path))
    start_event <- tibble(
      file = session_id,
      event = "START",
      timestamp = as.POSIXct(creation_ts, origin = "1970-01-01", tz = "UTC")
    )
    # Try to get actual events
    events <- tmp$elements$items[[1]]$result$events
    if (!is.null(events) && is.list(events)) {
      real_events <- map_dfr(events, function(e) {
        tibble(
          sessionID = session_id,
          event = e$event,
          timestamp = as.POSIXct(e$timestamp / 1000, origin = "1970-01-01", tz = "UTC"),
          progress = e$progress
        )
      })
      # Combine "START" with real events
      bind_rows(start_event, real_events)
    } else {
      # No events, return just the START
      start_event
    }
  }, error = function(e) {
    # On error, return empty tibble
    tibble()
  })
}


# Run the extraction across all files
all_events <- map_dfr(json_files, extract_events_from_file)


# Fill all the sessionID NAs
all_events_filled <- all_events %>%
  arrange(desc(row_number())) %>%
  fill(sessionID, .direction = "down") %>%
  arrange(row_number())

all_events_filled <- all_events_filled %>%
  arrange(desc(row_number()))  %>%
  fill(file, .direction = "down")

data_raw$file <- sub("\\.json$", "", data_raw$file)

# Create full data table
full_data <- left_join(all_events_filled, data_raw, by = "file")

full_data <- full_data %>%
  mutate(file_id = paste0(dense_rank(file)))

full_data <- full_data %>%
  mutate(session_id = paste0(dense_rank(sessionID)))

# The code below showed that file and sessionID identified the same things.
mean(full_data$session_id == full_data$file_id)

full_data <- full_data %>%
  select(-sessionID, -file_id)

# Adding row whether hint event was spammed or not
full_data <- full_data %>%
  arrange(session_id, timestamp) %>%  # ensure chronological order
  group_by(session_id) %>%
  mutate(
    time_diff = timestamp - lag(timestamp),
    prev_hint = lag(event) == "HINT",
    spam_hint = case_when(
      event == "HINT" & prev_hint & time_diff <= 3 ~ 1, # here I set spamming to requesting a hint in less than 5 seconds
      event == "HINT" ~ 0,
      TRUE ~ NA_real_
    )
  )

#include rows where event 1 and event 2 are both hints
consecutive_hints <- full_data %>%
  arrange(session_id, timestamp) %>%
  group_by(session_id) %>%
  mutate(
    prev_event = lag(event),
    time_between_hints = as.numeric(timestamp - lag(timestamp), units = "secs")
  ) %>%
  filter(event == "HINT" & prev_event == "HINT") %>%
  ungroup()

#plot the density on y axis and x axis is time between consecutive hints
ggplot(consecutive_hints, aes(x = time_between_hints)) +
  geom_density(fill = "skyblue", alpha = 0.6) +
  geom_vline(xintercept = 3, linetype = "dashed", colour = "red", linewidth = 0.7) +
  labs(
    title = "Density of Time Between Consecutive hint Requests",
    x = "Time Between Hints (seconds)",
    y = "Density"
  ) +
  theme_minimal() +
  xlim(c(0, 20))

#do the same for spamming evaluate
full_data <- full_data %>% 
  arrange(session_id, timestamp) %>%  # ensure chronological order
  group_by(session_id) %>%
  mutate(
    time_diff_eval = timestamp - lag(timestamp),
    prev_eval = lag(event) == "EVALUATE",
    spam_eval = case_when(
      event == "EVALUATE" & prev_eval & time_diff_eval <= 3 ~ 1, # here I set spamming to requesting a hint in less than 3 seconds
      event == "EVALUATE" ~ 0,
      TRUE ~ NA_real_
    )
  ) %>% 
  ungroup()

#include rows where event 1 and event 2 are both evaluate, and evaluate 2 is incorrect
consecutive_evals <- full_data %>%
  arrange(session_id, timestamp) %>%
  group_by(session_id) %>%
  mutate(
    prev_event = lag(event),
    prev_progress = lag(progress),
    time_between_evals = as.numeric(timestamp - lag(timestamp), units = "secs")
  ) %>%
  filter(
    event == "EVALUATE",
    prev_event == "EVALUATE",
    progress <= prev_progress  # progress did not increase
  ) %>%
  ungroup()


#plot the density on y axis and x axis is time between consecutive evaluates
ggplot(consecutive_evals, aes(x = time_between_evals)) +
  geom_density(fill = "skyblue", alpha = 0.6) +
  geom_vline(xintercept = 3, linetype = "dashed", colour = "red", linewidth = 0.7) +
  labs(
    title = "Density of Time Between Consecutive Evaluates",
    x = "Time Between Evaluates (seconds)",
    y = "Density"
  ) +
  theme_minimal() +
  xlim(c(0, 60))

full_data <- full_data %>%
  select(-time_diff_eval, -prev_eval)

full_data <- full_data %>%
  select(-time_diff, -prev_hint)


# First data exploration - when using a hint, what proportion spam the hint
mean(full_data$spam_hint, na.rm = TRUE)

################################################################################ 
# Adding difficulty did not seem possible as its not a variable in the data

# Tidying the environment
rm(all_events, interaction_row, items_df, out, results, tmp, i)

#check number of times where hints or eval were spammed, as well as total number of cases with consecutive hints or evals
full_data %>% filter(spam_hint == c(0, 1))
full_data %>% filter(spam_hint == 1)
full_data %>% filter(spam_eval == c(0, 1))
full_data %>% filter(spam_eval == 1)

#proportion of cases where hint was spammed (cases, not people)
25/3855

#proportion where eval was spammed (cases, not people) - this is also given the second eval was wrong
13424/67114

#comparing whether people who spam hints get the right answer in the end (correct vs incorrect)
#code might be incorrect, and does not count individual sessions, rather each event
#full_data %>% 
#  filter(event == "HINT") %>% 
#  group_by(spam_hint) %>% 
#  summarise(correct = mean(correct_answer == 1), incorrect = mean(correct_answer == 0))

#full_data %>% 
#  filter(event == c("EVALUATE", "HINT")) %>% 
#  group_by(event, spam_hint, spam_eval) %>% 
#  summarise(correct = mean(correct_answer == 1), incorrect = mean(correct_answer == 0))


#out of all sessions, we check how many spammed evaluate and got it wrong in the end
full_data %>% 
  filter(spam_eval == 1 & correct_answer == 0) %>% 
  distinct(file, .keep_all = TRUE)

#comparing whether people who spam evaluate get the right answer in the end
full_data %>% 
  filter(event == "EVALUATE") %>% 
  group_by(spam_eval) %>% 
  summarise(correct = mean(correct_answer == 1), incorrect = mean(correct_answer == 0))
#doesn't make a difference in whether they get the answer correct


#initial response is incorrect or there is no response before pressing hint, do they use hint afterwards or not?
session_behaviours <- full_data %>%
  group_by(session_id) %>%
  summarise(
    events = list(event),
    progresses = list(progress)
  ) %>%
  mutate(
    # Condition 1: First two events are START then HINT
    start_then_hint = map_lgl(events, ~ length(.) >= 2 && .[[1]] == "START" && .[[2]] == "HINT"),
    
    # Condition 2: First EVALUATE is incorrect, followed by any HINT
    hint_after_wrong = map2_lgl(events, progresses, function(ev, prog) {
      eval_indices <- which(ev == "EVALUATE")
      hint_indices <- which(ev == "HINT")
      if (length(eval_indices) == 0 || length(hint_indices) == 0) return(FALSE)
      first_eval <- eval_indices[1]
      first_eval_correct <- !is.na(prog[[first_eval]]) && prog[[first_eval]] == 1
      return(!first_eval_correct && any(hint_indices > first_eval))
    }),
    
    # Combined flag
    used_hint_after_start_or_wrong = start_then_hint | hint_after_wrong
  )

full_data <- left_join(full_data, session_behaviours %>% select(session_id, used_hint_after_start_or_wrong),
                       by = "session_id")

#proportion of people who used a hint after start or wrong answer
full_data %>%
  distinct(session_id, used_hint_after_start_or_wrong) %>%
  summarise(proportion = mean(used_hint_after_start_or_wrong, na.rm = TRUE))


#check whether people improve after pressing "evaluate" - using progress
#code might not be fully correct, check for logic
data_eval <- full_data %>%
  filter(event == "EVALUATE") %>%
  arrange(session_id, timestamp) %>% 
  group_by(session_id) %>%
  mutate(
    progress1 = progress,
    progress2 = lead(progress),
    improved = case_when(
      !is.na(progress1) & !is.na(progress2) & progress2 > progress1 ~ "Improved",
      !is.na(progress1) & !is.na(progress2) & progress2 <= progress1 ~ "No improvement",
      TRUE ~ NA_character_
    )
  ) %>%
  ungroup()

#remove NAs in improved column, and then do calculations
#proportion of people who improved vs didnt improve after pressing "evaluate" once
data_eval %>%
  filter(!is.na(improved)) %>%
  summarise(Improved = mean(improved == "Improved"), No_improvement = mean(improved == "No improvement"))






