library(tidyverse)
library(jsonlite)

#clear workspace
rm(list = ls())

file_path <- "~/Documents/Pressure-Cooker-Group-2/sessionInfo"

# Recursively find all JSON files under 'sessionInfo'
json_files <- list.files(path = file_path, 
                         pattern = "\\.json$", 
                         full.names = TRUE, 
                         recursive = TRUE)

results <- list()

for (i in seq_along(json_files)) {
  file_path <- json_files[i]
  try({
    tmp <- fromJSON(txt = file_path)
    items_df <- tmp$elements$items[[1]]
    interaction_row <- items_df[!is.na(items_df$interactionType), ]
    out <- tibble(
      file = basename(file_path),
      correct_answer = tmp$scoring$marksEarned,
      hints_requested = tmp$scoring$penalties$hintsRequested,
      content = interaction_row$interactionType,
      maybe_person_id = interaction_row$id
      #marks_total = tmp$scoring$marksTotal only adds a column of 1s
    )
    results[[i]] <- out
  }, silent = TRUE)
}

# Combine all extracted rows into a single data frame
data_raw <- bind_rows(results)

#extract all events and timestamps for each session
extract_events_from_file <- function(file_path) {
  tryCatch({
    tmp <- fromJSON(file_path)
    # Extract creation timestamp and convert to POSIX
    creation_ts <- tmp$creationTimestamp
    session_id <- tools::file_path_sans_ext(basename(file_path))
    start_event <- tibble(
      file = session_id,
      event = "START",
      timestamp = as.POSIXct(creation_ts, origin = "1970-01-01", tz = "UTC")
    )
    # Try to get actual events
    events <- tmp$elements$items[[1]]$result$events
    if (!is.null(events) && is.list(events)) {
      real_events <- map_dfr(events, function(e) {
        tibble(
          sessionID = session_id,
          event = e$event,
          timestamp = as.POSIXct(e$timestamp / 1000, origin = "1970-01-01", tz = "UTC")
        )
      })
      # Combine "START" with real events
      bind_rows(start_event, real_events)
    } else {
      # No events, return just the START
      start_event
    }
  }, error = function(e) {
    # On error, return empty tibble
    tibble()
  })
}


# Run the extraction across all files
all_events <- map_dfr(json_files, extract_events_from_file)


# Fill all the sessionID NAs
all_events_filled <- all_events %>%
  arrange(desc(row_number())) %>%
  fill(sessionID, .direction = "down") %>%
  arrange(row_number())

all_events_filled <- all_events_filled %>%
  arrange(desc(row_number()))  %>%
  fill(file, .direction = "down")
  
data_raw$file <- sub("\\.json$", "", data_raw$file)

# Create full data table
full_data <- left_join(all_events_filled, data_raw, by = "file")

full_data <- full_data %>%
  mutate(file_id = paste0(dense_rank(file)))
  
full_data <- full_data %>%
  mutate(session_id = paste0(dense_rank(sessionID)))

# The code below showed that file and sessionID identified the same things.
mean(full_data$session_id == full_data$file_id)

full_data <- full_data %>%
  select(-sessionID, -file_id)
  
# Adding row whether hint event was spammed or not
full_data <- full_data %>%
  arrange(session_id, timestamp) %>%  # ensure chronological order
  group_by(session_id) %>%
  mutate(
    time_diff = timestamp - lag(timestamp),
    prev_hint = lag(event) == "HINT",
    spam_hint = case_when(
      event == "HINT" & prev_hint & time_diff <= 3 ~ 1, # here I set spamming to requesting a hint in less than 3 seconds
      event == "HINT" ~ 0,
      TRUE ~ NA_real_
    )
  ) %>%
  ungroup()

full_data <- full_data %>%
  select(-time_diff, -prev_hint)

# First data exploration
mean(full_data$rapid_hint, na.rm = TRUE)
  
################################################################################ 
# Adding difficulty did not seem possible as its not a variable in the data

# Tidying the environment
rm(all_events, interaction_row, items_df, out, results, stuff, tmp, i)






